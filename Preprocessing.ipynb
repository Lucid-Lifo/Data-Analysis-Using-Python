{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucid-Lifo/Data-Analysis-Using-Python/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koR1DMMKyEpX"
      },
      "source": [
        "## Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkzAi_1MyEp4"
      },
      "outputs": [],
      "source": [
        "#Importing necessory packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df=pd.read_csv( 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv ', sep=';')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcJLp5QHyEqF"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-wjRjv2bzGE"
      },
      "source": [
        "## Exporting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws_wHBLJbxx9"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lPJ4xZ3ZNBA"
      },
      "source": [
        "##Basic statistical insights from datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7U7rDG4yEqH"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prp2M5sqyEqH"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYNiljMyB6Z3"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97pxNGcRyEqG"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvagrhC00XiD"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIGvNUkOyEqI"
      },
      "outputs": [],
      "source": [
        "df.groupby('quality').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Ges1YZw8A1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4n3n-7NyEqQ"
      },
      "outputs": [],
      "source": [
        "dataset1 = pd.read_csv('/content/drive/MyDrive/Lectures/2025-2026 First Half/MCA/Module 4/Placement_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v58ntJQnyEqT"
      },
      "outputs": [],
      "source": [
        "dataset1.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GtsQrO0yEqU"
      },
      "outputs": [],
      "source": [
        "dataset1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYLJ6JEEcNKc"
      },
      "source": [
        "# Data cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grzMFt2DZyq9"
      },
      "source": [
        "## Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn_2R7g1yEqV"
      },
      "outputs": [],
      "source": [
        "dataset1.isnull().sum() #Checking for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc117KVkyEqW"
      },
      "source": [
        "#### impute methods\n",
        "1. Mean\n",
        "2. Median\n",
        "3. Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdJGxOTcyEqW"
      },
      "outputs": [],
      "source": [
        "dataset1['salary'].fillna(dataset1['salary'].median(),inplace=True)   #Replace the missing values with Median value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBkGQNEayEqX"
      },
      "outputs": [],
      "source": [
        "dataset1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAEN-aFwyEqY"
      },
      "outputs": [],
      "source": [
        "# filling missing values with Mean value:\n",
        "# dataset['salary'].fillna(dataset['salary'].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFbKBk3Sp6cM"
      },
      "outputs": [],
      "source": [
        "# filling missing values with Mean value:\n",
        "# dataset['salary'].fillna(dataset['salary'].mode(),inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XObpu1NMciis"
      },
      "source": [
        "##### Drop method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCa7PIulyEqZ"
      },
      "outputs": [],
      "source": [
        "salary_dataset = pd.read_csv('/content/drive/MyDrive/Lectures/2025-2026 First Half/MCA/Module 4/Placement_Dataset.csv')\n",
        "\n",
        "salary_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ra1k02zyEqZ"
      },
      "outputs": [],
      "source": [
        "salary_dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSDe8btZyEqa"
      },
      "outputs": [],
      "source": [
        "salary_dataset = salary_dataset.dropna(how='any')   # drop the row with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUq5h_EPyEqa"
      },
      "outputs": [],
      "source": [
        "salary_dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjxX6zPVyEqa"
      },
      "outputs": [],
      "source": [
        "salary_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmXPq_DGyEqb"
      },
      "source": [
        "# Transformation\n",
        "\n",
        "##### Use of Scikit library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4w4SjtLyEqb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv ',sep=';')\n",
        "\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdXn0IpLcft5"
      },
      "outputs": [],
      "source": [
        "df['fixed acidity'].corr(df['volatile acidity'])   #correlation between two features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olCkdGQgyilD"
      },
      "outputs": [],
      "source": [
        "array=df.values\n",
        "#Separating data into input and output components\n",
        "x=array[:,0:8]\n",
        "\n",
        "y=array[:,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh4smHqwyEqc"
      },
      "outputs": [],
      "source": [
        "print(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khcrrSk0yEqh"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXfwBLF_yEqi"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeM5KuT7aZTH"
      },
      "source": [
        "### Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOOCoIdnyEqj"
      },
      "outputs": [],
      "source": [
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "rescaledX = scaler.fit_transform(x)\n",
        "\n",
        "rescaledX[0:5,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZX3AdWuyEqj"
      },
      "source": [
        "### Standardizing Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZRPaVJMyEqk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler().fit(x)     # removing the mean and scaling to unit variance\n",
        "\n",
        "rescaledX=scaler.transform(x)\n",
        "rescaledX[0:5,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLnGUCCgyEql"
      },
      "source": [
        "### Robust Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oQ6JCPuyEqm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "robust_scaler = RobustScaler()          #leverages robust statistics: the median and the Interquartile Range (IQR).\n",
        "transformed = robust_scaler.fit_transform(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqPIVjCPyEqm"
      },
      "outputs": [],
      "source": [
        "transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64gidSayEqk"
      },
      "source": [
        "### Normalizing Data\n",
        "\n",
        "### Unlike StandardScaler or MinMaxScaler which operate on features (columns), Normalizer works on samples (rows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFJpsxkLyEqk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "scaler=Normalizer().fit(x)        #Normalizes the sum of the squares of the components to 1\n",
        "normalizedX=scaler.transform(x)\n",
        "normalizedX[0:5,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTVn25SOyEql"
      },
      "source": [
        "### Binarizing Data\n",
        "\n",
        "### convert numerical feature values into binary (0 or 1) values based on a specified threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VEs8G2gyEql"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "binarizer=Binarizer(threshold=0.0).fit(x)\n",
        "binaryX=binarizer.transform(x)\n",
        "binaryX[0:5,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDX1MXvTyEqn"
      },
      "source": [
        "### Label Encoding\n",
        "\n",
        "### Label encoding in scikit-learn is a technique used to convert categorical labels into numerical format, which is necessary for many machine learning algorithms that require numerical input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4PHZqHTyEqn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder=LabelEncoder()\n",
        "\n",
        "input_classes=['Havells','Philips','Syska','Eveready','Lloyd']\n",
        "label_encoder.fit(input_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huYY-1QQyEqn"
      },
      "outputs": [],
      "source": [
        "for i,item in enumerate(label_encoder.classes_):\n",
        "    print(item,'-->',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH_RSqGNyEqo"
      },
      "outputs": [],
      "source": [
        "labels=['Lloyd','Syska','Philips']\n",
        "label_encoder.transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FrLEHW3yEqo"
      },
      "outputs": [],
      "source": [
        "label_encoder.inverse_transform(label_encoder.transform(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TeDdnqcyEqp"
      },
      "source": [
        "### One hot encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPejXavCyEqp",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_data = [\"apple\", \"mango\", \"apple\", \"berry\", \"mango\", \"apple\", \"berry\", \"apple\"]\n",
        "\n",
        "label = LabelEncoder()\n",
        "\n",
        "int_data = label.fit_transform(cat_data)\n",
        "int_data = int_data.reshape(len(int_data), 1)\n",
        "print(int_data)\n",
        "\n",
        "onehot_data = OneHotEncoder(sparse_output=False)\n",
        "onehot_data = onehot_data.fit_transform(int_data)\n",
        "print(\"\\nCategorical data encoded into integer values....\\n\")\n",
        "print(onehot_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrVyYx3hYlpR"
      },
      "outputs": [],
      "source": [
        "#create DataFrame\n",
        "df = pd.DataFrame({'points': [25, 12, 15, 14, 19, 23, 25, 29],\n",
        "                   'assists': [5, 7, 7, 9, 12, 9, 9, 4],\n",
        "                   'rebounds': [11, 8, 10, 6, 6, 5, 9, 12]})\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KiR8SQSYm4T"
      },
      "outputs": [],
      "source": [
        "#calculate correlation between points and assists\n",
        "df['points'].corr(df['assists'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkeg-APUecQQ"
      },
      "source": [
        "## Example- Preprocessing Stages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKUPPB1BdtRg"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymQS3yHjdtRg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIklZKIYdtRh"
      },
      "source": [
        "## 2. Load a Built-in Dataset (Iris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPRj_AGCdtRi"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data  # features\n",
        "y = iris.target  # labels\n",
        "\n",
        "print('Feature names:', iris.feature_names)\n",
        "print('Target names:', iris.target_names)\n",
        "print('Shape of X:', X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvtkQ6QadtRi"
      },
      "source": [
        "## 3. Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCYJdZ7MdtRi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op6Chm9IdtRj"
      },
      "source": [
        "## 4. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbAmZKJRdtRj"
      },
      "outputs": [],
      "source": [
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Mean of scaled training data:\", X_train_scaled.mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}